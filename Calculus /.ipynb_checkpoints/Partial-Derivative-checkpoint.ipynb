{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partial Derivative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partial deriviative is how the derivative is changed form one \"part\" of the derivative (the derivative of just x given the function f(x) for example). If represented on a line for two dimentions we see either a vector pointing left or right and the value of the vector. From that vector, value pair we can see how the function is increaing or decreasing from 0 and chahge values corisponding to that to get it as close to 0 as posible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caclulate the partial derivative from definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0000010006480125\n",
      "-3.9999959997594203\n"
     ]
    }
   ],
   "source": [
    "def f(x, y):\n",
    "    return (x**2)/y\n",
    "\n",
    "eps = 1e-6\n",
    "x = 2\n",
    "y = 1\n",
    "print((f(x + eps, y) - f(x, y)) / eps)\n",
    "print((f(x, y + eps) - f(x, y)) / eps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why do we need parial Gradiants?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cost Function: a function used in machine learning to help correct / change behaviour to minimize mistakes. Or in other words, a measure of how wrong the model is in terms of its ability to estimate the relationship between x and y. Source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want parial grdiants (partial derivatives) because they allow us whether or not the cost function is increacing or decreasing at a single point in the function. Once we know wether or not the current loss (output of the cost function) is increacing or decreacing from 0, we know how we should change the weights of the function in order to change the output of the loss function and get it as close to 0 (minimum loss and/or a derivative of 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
